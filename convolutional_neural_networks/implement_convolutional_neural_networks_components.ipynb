{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Convolutional Neural Networks components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X - data type is numpy array, shape (m, H, W, C)\n",
    "    pad - data type is integer, amount of padding around each image on vertical and horizontal\n",
    "    \"\"\"\n",
    "    padded_X = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), \"constant\", constant_values=0)\n",
    "    return padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117059898>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "m = 4 # Number of sample\n",
    "H = 3 # Height\n",
    "W = 3 # Width\n",
    "C = 2 # Channel\n",
    "\n",
    "X = np.random.randn(m, H, W, C)\n",
    "padded_X = zero_pad(X, 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].set_title(\"X\")\n",
    "axes[0].imshow(X[0, :, :, 0])\n",
    "axes[1].set_title(\"Padded X\")\n",
    "axes[1].imshow(padded_X[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation\n",
    "\n",
    "\n",
    "### Convolutional layer forward\n",
    "\n",
    "$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor + 1 $\n",
    "\n",
    "$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor + 1 $\n",
    "\n",
    "$ n_C = \\text{Number of filters used in the convolution} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_conv(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_slice_prev - data type is numpy array, shape is (f, f, C_prev)\n",
    "    W - data type is numpy array, Weights matrix, shape is (f, f, C_prev)\n",
    "    b - data type is numpy array, bias matrix, shape is (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z - a scalar value, result of convolving the sliding window (W, b) on a slice x of he input data\n",
    "    \"\"\"\n",
    "    \n",
    "    single = np.multiply(a_slice_prev, W)\n",
    "    Z = np.sum(single)\n",
    "    Z = Z + float(b)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4 ,3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "Z = single_step_conv(a_slice_prev, W, b)\n",
    "print(\"Z = {}\".format(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hyper_params):\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    stride = hyper_params[\"stride\"]\n",
    "    pad = hyper_params[\"pad\"]\n",
    "    \n",
    "    \n",
    "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    padded_A_prev = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_padded_prev = padded_A_prev[i]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = h * stride + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = w * stride + f\n",
    "                    \n",
    "                    a_slice_prev = a_padded_prev[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    Z[i, h, w, c] = single_step_conv(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
    "    \n",
    "    cache = (A_prev, W, h, hyper_params)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z.shape = (10, 4, 4, 8)\n",
      "Z[4, 2, 1, :] = [-0.20555171  6.23776201  2.00711797  0.76155097 -6.17175943  0.2447692\n",
      "  5.37072111  3.46037289]\n"
     ]
    }
   ],
   "source": [
    "np.random.randn(1)\n",
    "A_prev = np.random.randn(10, 4, 4, 3)\n",
    "W = np.random.randn(2, 2, 3, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hyper_params = {\"pad\": 2, \"stride\": 2}\n",
    "\n",
    "\n",
    "Z, conv_cache = conv_forward(A_prev, W, b, hyper_params)\n",
    "print(\"Z.shape = {}\".format(Z.shape))\n",
    "print(\"Z[4, 2, 1, :] = {}\".format(Z[4, 2, 1, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer forward\n",
    "\n",
    "The pooling layer reduces the dimations of the intpu.\n",
    "\n",
    "$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor + 1 $\n",
    "\n",
    "$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor + 1 $\n",
    "\n",
    "$ n_C = n_{C_{prev}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hyper_params, mode=\"max\"):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    f = hyper_params[\"f\"]\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    \n",
    "    n_H = int((n_H_prev - f) / stride + 1)\n",
    "    n_W = int((n_W_prev - f) / stride + 1)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = h * stride + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = w * stride + f\n",
    "                    \n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    cache = (A_prev, hyper_params)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_prev = [[[[ 2.50598029e+00  1.91979229e+00 -1.39169388e+00]\n",
      "   [ 4.50217742e-01  6.27437083e-01  7.51337235e-01]\n",
      "   [ 1.40395436e-01 -9.26871939e-01 -1.82420406e-01]\n",
      "   [-4.91125138e-01  1.34373116e-01 -2.68371304e-01]]\n",
      "\n",
      "  [[-1.31675626e-01  1.01855247e+00  1.23055820e+00]\n",
      "   [-1.18110317e+00 -4.59930104e-01 -7.90799954e-01]\n",
      "   [ 1.22372221e+00 -5.93679025e-02  1.44898940e+00]\n",
      "   [-4.77580855e-01  2.59999942e-02 -1.34869645e+00]]\n",
      "\n",
      "  [[ 1.30253554e+00 -3.62612088e-01 -1.48515645e+00]\n",
      "   [-5.92461285e-01 -2.30490794e+00 -3.18171727e-02]\n",
      "   [ 1.12487742e-01  2.88078167e-01  1.49810818e+00]\n",
      "   [-3.00976154e-01  8.07455917e-01  3.12238689e-01]]\n",
      "\n",
      "  [[-1.93321640e-01 -2.07680202e+00  9.47501167e-01]\n",
      "   [-5.03973949e-01  1.79558917e-02 -1.27046078e+00]\n",
      "   [ 2.82995534e-01  1.08030817e-01  2.94176190e-02]\n",
      "   [-1.34793129e-01  1.04921829e+00  9.66220863e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.25916853e-01  3.32107876e+00 -6.00225330e-01]\n",
      "   [-3.79517516e-01 -1.01480369e+00  4.35986196e-01]\n",
      "   [-6.87487393e-01 -2.69836174e+00 -1.21333813e+00]\n",
      "   [ 7.22518992e-02  1.00978733e+00 -1.55694156e+00]]\n",
      "\n",
      "  [[-6.12442128e-01 -1.39351805e-01 -7.28537489e-01]\n",
      "   [ 5.31163793e-01  4.00084198e-03  3.21265914e-01]\n",
      "   [-7.25214926e-01  1.53653633e+00 -3.75008758e-04]\n",
      "   [ 1.29354962e+00 -4.38997664e-01  5.90039464e-01]]\n",
      "\n",
      "  [[-6.79383783e-01 -9.50909251e-01 -7.04350332e-01]\n",
      "   [-4.58666861e-02 -2.18733459e-01  1.53920701e+00]\n",
      "   [-1.14870423e+00 -1.09033833e+00  1.70018815e+00]\n",
      "   [ 6.08783659e-01 -1.88141087e+00  4.97269099e-01]]\n",
      "\n",
      "  [[ 2.37332699e-01 -2.14444405e+00 -3.69562425e-01]\n",
      "   [-1.74549518e-02  7.31402517e-01  9.54495667e-01]\n",
      "   [ 9.57467711e-02  1.03345080e+00 -1.46273275e-01]\n",
      "   [-8.57496825e-01 -9.34181843e-01  5.42645295e-01]]]]\n",
      "A = [[[[2.50598029 1.91979229 1.2305582 ]\n",
      "   [1.22372221 0.13437312 1.4489894 ]]\n",
      "\n",
      "  [[1.30253554 0.01795589 0.94750117]\n",
      "   [0.28299553 1.04921829 1.49810818]]]\n",
      "\n",
      "\n",
      " [[[0.72591685 3.32107876 0.4359862 ]\n",
      "   [1.29354962 1.53653633 0.59003946]]\n",
      "\n",
      "  [[0.2373327  0.73140252 1.53920701]\n",
      "   [0.60878366 1.0334508  1.70018815]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.randn(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hyper_params = {\"stride\": 2, \"f\": 2}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hyper_params)\n",
    "\n",
    "print(\"A_prev = {}\".format(A_prev))\n",
    "print(\"A = {}\".format(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward propagation\n",
    "\n",
    "### Convolutional layer backward\n",
    "\n",
    "$ dA = \\sum_{n_H}^{h = 0} \\sum_{n_w}^{w = 0} W_c \\times dZ_{hw} $\n",
    "\n",
    "$ dW_c  += \\sum_{n_H}^{h = 0} \\sum_{n_W}^{w = 0} a_{slice} \\times dZ_{hw} $\n",
    "\n",
    "$ db = \\sum_{h} \\sum_{w} dZ_{hw} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    (A_prev, W, b, hyper_params) = cache\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    stride = hyper_params[\"stride\"]\n",
    "    pad = hyper_params[\"pad\"]\n",
    "    \n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "    \n",
    "    padded_A_prev = zero_pad(A_prev, pad)\n",
    "    padded_dA_prev = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        padded_a_prev = padded_A_prev[i]\n",
    "        padded_da_prev = padded_dA_prev[i]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = h * stride + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = w * stride + f\n",
    "                    \n",
    "                    a_slice = padded_a_prev[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    padded_da_prev[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, C] * dZ[i , h, w, c]\n",
    "                    dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:, :, :, c] += dZ[i, h, w, c]\n",
    "        dA_prev[i, :, :, :] = padded_da_prev[pad:-pad, pad:-pad, :]\n",
    "    return dA_prev, dW, db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA.shape = (10, 4, 4, 3)\n",
      "dW.shape = (2, 2, 3, 8)\n",
      "db.shape = (1, 1, 1, 8)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dA, dW, db = conv_backward(Z, conv_cache)\n",
    "print(\"dA.shape = {}\".format(dA.shape))\n",
    "print(\"dW.shape = {}\".format(dW.shape))\n",
    "print(\"db.shape = {}\".format(db.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer backward\n",
    "\n",
    "* Max pooling\n",
    "\n",
    "$ X = \\begin{bmatrix} 1 \\quad 3 \\\\ 4 \\quad 2 \\end{bmatrix} \\quad M = \\begin{bmatrix} 0 \\quad 0 \\\\ 1 \\quad 0 \\end{bmatrix} $\n",
    "\n",
    "* Average pooling\n",
    "\n",
    "$ dZ = 1 \\rightarrow dZ = \\begin{bmatrix} 1/4 \\quad 1/4 \\\\ 1/4 \\quad 1/4 \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_maxk_from_window(x):\n",
    "    mask = (x == np.max(x))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[ 1.62434536 -0.61175641]\n",
      " [-0.52817175 -1.07296862]]\n",
      "mask = [[ True False]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2, 2)\n",
    "mask = create_maxk_from_window(x)\n",
    "print(\"x = {}\".format(x))\n",
    "print(\"mask = {}\".format(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    (n_H, n_W) = shape\n",
    "    average = dz / (n_H * n_W)\n",
    "    a = np.ones(shape) * average\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribute value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2, 2))\n",
    "print(\"Distribute value = {}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode=\"max\"):\n",
    "    (A_prev, hyper_params) = cache\n",
    "    f = hyper_params[\"f\"]\n",
    "    stride = hyper_params[\"stride\"]\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (m, n_H, n_W, n_C) = dA.shape\n",
    "    \n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = h * stride + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = w * stride + f\n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = create_maxk_from_window(a_prev_slice)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n",
    "                    elif mode == \"average\":\n",
    "                        da = dA[i, h, w, c]\n",
    "                        shape = (f, f)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)\n",
    "                        \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [[[[ 1.74481176 -0.24937038]\n",
      "   [ 1.46210794 -0.24937038]]\n",
      "\n",
      "  [[ 1.74481176 -0.24937038]\n",
      "   [ 1.46210794 -0.24937038]]\n",
      "\n",
      "  [[ 1.13376944  1.14472371]\n",
      "   [ 1.13376944  1.14472371]]\n",
      "\n",
      "  [[ 0.90085595  1.14472371]\n",
      "   [ 0.90159072  1.14472371]]]\n",
      "\n",
      "\n",
      " [[[ 1.65980218  0.74204416]\n",
      "   [ 1.65980218  0.74204416]]\n",
      "\n",
      "  [[ 1.65980218  1.6924546 ]\n",
      "   [ 1.65980218  2.10025514]]\n",
      "\n",
      "  [[ 0.30017032  1.6924546 ]\n",
      "   [ 0.30017032  2.10025514]]\n",
      "\n",
      "  [[ 0.83898341  0.93110208]\n",
      "   [ 0.83898341  0.93110208]]]\n",
      "\n",
      "\n",
      " [[[ 2.18557541  1.51981682]\n",
      "   [ 2.18557541 -0.07557171]]\n",
      "\n",
      "  [[ 2.18557541  1.51981682]\n",
      "   [ 2.18557541  0.82797464]]\n",
      "\n",
      "  [[ 0.31563495  0.87616892]\n",
      "   [ 0.31563495  0.82797464]]\n",
      "\n",
      "  [[ 0.23009474  0.76201118]\n",
      "   [ 0.18656139  1.12948391]]]\n",
      "\n",
      "\n",
      " [[[ 1.19891788  0.69803203]\n",
      "   [ 0.42349435  1.2245077 ]]\n",
      "\n",
      "  [[ 0.40349164  0.69803203]\n",
      "   [ 0.74055645  1.2245077 ]]\n",
      "\n",
      "  [[ 0.40349164  0.59357852]\n",
      "   [ 0.84616065  0.31515939]]\n",
      "\n",
      "  [[ 0.35054598  0.31515939]\n",
      "   [ 1.12141771  0.40890054]]]\n",
      "\n",
      "\n",
      " [[[ 1.62765075  1.96710175]\n",
      "   [ 1.27375593  1.96710175]]\n",
      "\n",
      "  [[ 1.62765075  0.86334532]\n",
      "   [ 0.79280687  0.86334532]]\n",
      "\n",
      "  [[ 0.80186103  0.5505375 ]\n",
      "   [ 0.86888616  0.75041164]]\n",
      "\n",
      "  [[ 0.80186103  0.61838026]\n",
      "   [ 0.86888616  0.75041164]]]]\n",
      "dA = [[[[ 0.          0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.13124767  0.        ]\n",
      "   [ 0.         -0.46706754]\n",
      "   [ 0.90237986  0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [-0.49968505  0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.         -2.59038987]\n",
      "   [ 0.49521132  0.        ]]\n",
      "\n",
      "  [[ 0.24879916  0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 5.05844394 -1.68282702]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.67517265]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.         -0.53594264]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 1.37512611  0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [-0.59248892 -0.00625388]\n",
      "   [ 0.          0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.         -0.61736206]]\n",
      "\n",
      "  [[ 0.          1.53396297]\n",
      "   [ 1.23616396  0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.36949272]\n",
      "   [ 3.06499728  0.        ]\n",
      "   [ 0.          1.03794399]]\n",
      "\n",
      "  [[ 0.6590498  -1.62743834]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.60231928  0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 0.          0.4202822 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.81095167  0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [-0.40087819  0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          2.99932017]\n",
      "   [ 0.         -0.93668294]]\n",
      "\n",
      "  [[-2.2130267  -0.89055558]\n",
      "   [ 0.          0.        ]\n",
      "   [-1.33195167  0.        ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.          0.61340311]\n",
      "   [-1.1191154   0.        ]]\n",
      "\n",
      "  [[-0.3264995   0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [ 1.11438298 -0.58652394]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.        ]\n",
      "   [ 0.62336218  0.44088224]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.17068662  0.        ]\n",
      "   [ 0.          0.63184246]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 0.          0.1094027 ]\n",
      "   [ 1.6169496   0.        ]\n",
      "   [ 0.          0.        ]]\n",
      "\n",
      "  [[ 1.01303137  0.        ]\n",
      "   [ 0.          0.        ]\n",
      "   [-1.9201429   2.2459742 ]]\n",
      "\n",
      "  [[ 0.          0.        ]\n",
      "   [ 0.         -0.19883786]\n",
      "   [ 0.          0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hyper_params = {\"f\": 2, \"stride\": 1}\n",
    "A, cache = pool_forward(A_prev, hyper_params)\n",
    "dA = np.random.randn(5, 4, 2 ,2)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache)\n",
    "print(\"A = {}\".format(A))\n",
    "print(\"dA = {}\".format(dA_prev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
